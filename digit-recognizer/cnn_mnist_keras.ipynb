{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score on kaggle: 0.99585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! remember to clear session/graph if you rebuild your graph to avoid out-of-memory errors !!!\n",
    "def reset_tf_session():\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    s = K.get_session()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PATH = 'train'\n",
    "VALIDATION_PATH = 'validation'\n",
    "ALL_TRAIN = 'all_train'\n",
    "TESTING_PATH = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_image(dirpath, csvpath, labels_given=False, validation_split=0.3):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.mkdir(dirpath)\n",
    "        print('Created directory \\'{}\\''.format(dirpath))\n",
    "    if labels_given and validation_split > 0:\n",
    "        if not os.path.exists('validation'):\n",
    "            os.mkdir('validation')\n",
    "    \n",
    "    print('Loading csv...')\n",
    "    df = pd.read_csv(csvpath)\n",
    "    if labels_given:\n",
    "        images = df.drop('label', axis=1).as_matrix()\n",
    "        labels = df['label'].map(str)\n",
    "    else:\n",
    "        images = df.as_matrix()\n",
    "    print('Loading csv complete.!')\n",
    "    \n",
    "    print('Saving Images..')\n",
    "    for i in range(len(images)):\n",
    "        # create image\n",
    "        img = Image.new('L', (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        img.putdata(images[i])\n",
    "        \n",
    "        # save\n",
    "        new_dir = dirpath\n",
    "        if labels_given:\n",
    "            if random.random() < validation_split:\n",
    "                new_dir = 'validation'\n",
    "            new_dir = os.path.join(new_dir, labels[i])\n",
    "        else:\n",
    "            new_dir = os.path.join(new_dir, 'dummy')\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.mkdir(new_dir)\n",
    "        \n",
    "        img.save(os.path.join(new_dir, '{:05d}'.format(i + 1) + '.jpg'))\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print('Saved', i)\n",
    "    print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_to_image('all_train', 'train.csv', True, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_to_image('train', 'train.csv', True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_to_image('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29469 images belonging to 10 classes.\n",
      "Found 12531 images belonging to 10 classes.\n",
      "Found 42000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "CLASSES = list(map(str, range(10)))\n",
    "train_batches = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                  shear_range=10, zoom_range=0.15).flow_from_directory(\n",
    "    TRAINING_PATH, target_size=(28, 28), batch_size=100, color_mode='grayscale')\n",
    "valid_batches = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                  shear_range=10, zoom_range=0.15).flow_from_directory(\n",
    "    VALIDATION_PATH, target_size=(28, 28), batch_size=100, color_mode='grayscale')\n",
    "all_train_batches = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                  shear_range=10, zoom_range=0.15).flow_from_directory(\n",
    "    ALL_TRAIN, target_size=(28, 28), batch_size=100, color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=128, kernel_size=(5, 5), padding='same', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    Conv2D(filters=128, kernel_size=(5, 5), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.1),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(300),\n",
    "    LeakyReLU(0.1),\n",
    "    Dense(250),\n",
    "    LeakyReLU(0.1),\n",
    "    Dense(200),\n",
    "    LeakyReLU(0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 128)       3328      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               38700     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               75250     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 1,468,816\n",
      "Trainable params: 1,466,768\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will save model checkpoints to continue training in case of kernel death\n",
    "model_filename = 'mnist.{0:03d}.hdf5'\n",
    "last_finished_epoch = None\n",
    "\n",
    "### uncomment below to continue training from model checkpoint\n",
    "### fill `last_finished_epoch` with your latest finished epoch\n",
    "from keras.models import load_model\n",
    "s = reset_tf_session()\n",
    "last_finished_epoch = 88\n",
    "model = load_model(model_filename.format(last_finished_epoch - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gen = model.fit_generator(train_batches, epochs=5, validation_data=valid_batches,\n",
    "#                     callbacks=[keras_utils.ModelSaveCallback(model_filename),\n",
    "#                                keras_utils.TqdmProgressCallback()],\n",
    "#                     verbose=2,\n",
    "#                     initial_epoch=last_finished_epoch or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen = model.fit_generator(all_train_batches, epochs=88,\n",
    "                    callbacks=[keras_utils.ModelSaveCallback(model_filename),\n",
    "                               keras_utils.TqdmProgressCallback()],\n",
    "                    verbose=2,\n",
    "                    initial_epoch=last_finished_epoch or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_finished_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator()\n",
    "test_batches = test_gen.flow_from_directory(\n",
    "    TESTING_PATH, target_size=(28, 28), batch_size=32, color_mode='grayscale', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABwklEQVR4nL2Su2sUYRTFf983385zsyYmiq9CIhbBB1ooiBCIlSBBG/8Kia1NwEqwsrS0SyMIIipaig9UsPIBBhTxAUpwE3dmmc3MzhyL3SAbrT3t5Xfvuede2JDxwFkSaBkmGVUTAkyMteN43mgtCAkhhEkw23CbUAMGgATiUXSMLfGu6Yn5e3f2baYArtdFmfb7OuTTIBqdefqV2qnqsvfi2Ym/3C7rl9aLspA6n47S3DBiPWsNc19VZ5emZy4W6i1ODSoGDdbMZmdid+sjPD+YYJoZgDUDGqwjIfA5k0l/DBvrOUcLiLAwLVVxDODAGKMKL2Os7lL7/hwqG9WQM2Y4nIafwMSDXOkYAM5TDVhLP+kePpDfJpwVH9IoB5ypwfihO+fOBkfG9Vj7q+j1qSAftHWwd+Fhro4yqVNqTVpeHKZngctakfJvbzqF1FO1rvTmMKGEqJJ+vDzPsSdtfWlfW3ikNd0FwGe76aa13q98fpuVWp2Hqfv5aroRglsq1VWnKvT0wkm2Wp/jujE4/47v+Huu7G4HP6++C/sUNEqjVlYDxLRo0sDgEwAhMQ2IB01bONgJEUQkGLAQ/ONT/o9+AwaCrAyXKnAbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A388147080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = next(test_batches)\n",
    "img = Image.new('L', (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "img.putdata(image[0][0].reshape(-1))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('submission.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 0, 3, 7, 0, 3, 0, 3, 5, 7, 4, 0, 4, 3, 3, 1, 9, 0, 9, 1,\n",
       "       1, 5, 7, 4, 2, 7, 4, 7, 7, 5], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_batches[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_batches.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageId  Label\n",
       "73       74      8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.ImageId==74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
